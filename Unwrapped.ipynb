{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbc57aa-dbfb-4f23-9195-55c65b85844d",
   "metadata": {},
   "source": [
    "# Spotify Unwrapped 2024\n",
    "Copy and paste Spotify and Genius API credentials below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc673d13-4b63-44c3-ac39-1879b0ee4563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spotify api credentials\n",
    "spotify_client_id = '' # client ID (make sure it's in quotation marks)\n",
    "spotify_client_secret = '' # client secret (make sure it's in quotation marks)\n",
    "\n",
    "# genius api credentials\n",
    "genius_access_token = '' # access token (make sure it's in quotation marks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efcef1a7-69b7-495a-b3c0-5c012767923a",
   "metadata": {},
   "source": [
    "Then run that cell (click in, hit shift+enter) and the one below. It should open a new browser tab that prompts you to log in to Spotify. Click authorize and then copy the browser link it redirects you to and paste in the pop-up that appears below this cell. The page will say \"this page could not be opened\" or something, that's fine.\n",
    "\n",
    "If it doesn't prompt you to do anything, just runs and doesn't output anything, that's fine too. Just continue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17d0561-1160-4744-8a15-d5b60feba744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy as spt\n",
    "from spotipy.oauth2 import SpotifyOAuth,SpotifyClientCredentials\n",
    "\n",
    "# spotify client credentials\n",
    "spu = spt.Spotify(auth_manager=SpotifyOAuth(\n",
    "    client_id=spotify_client_id,\n",
    "    client_secret=spotify_client_secret,\n",
    "    redirect_uri='http://localhost/callback',\n",
    "    scope='user-top-read playlist-read-private user-library-read',\n",
    "    cache_path='.cache-username'\n",
    "))\n",
    "\n",
    "results = spu.current_user_playlists(limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fbc151-bcc4-42f3-9f67-2840721139c1",
   "metadata": {},
   "source": [
    "Now click on \"1. Get data from Spotify\", then up to the top bar, then Run -> Run Selected Cell and All Below. This will take some time, especially to read all the Genius lyrics. Expect images to start appearing in a few minutes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fb086b-b923-4b2c-8eac-3425079000d6",
   "metadata": {},
   "source": [
    "### 1. Get data from Spotify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895c9210-9618-4486-996c-2fdf79f1d3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import lyricsgenius\n",
    "from textblob import TextBlob\n",
    "import re\n",
    "import joblib\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "import requests\n",
    "from io import BytesIO\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46afdb63-10cf-4296-91cb-286ce050a175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pulling most recent user playlist (top songs 2024)\n",
    "for item in results['items']:\n",
    "    if item is not None:\n",
    "        playlist_id = item['uri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a108ee-000b-440b-afb7-32cf386241ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting information about these songs from spotify api\n",
    "\n",
    "def get_playlist_songs(playlist):\n",
    "    track_ids = []\n",
    "    track_names = []\n",
    "    artist_ids = []\n",
    "    artist_names = []\n",
    "    release_date = []\n",
    "    popularity = []\n",
    "    length = []\n",
    "    \n",
    "    data = spu.playlist_items(playlist)\n",
    "    \n",
    "    for page in range(0, data['total'] // 100 + 1):\n",
    "        data = spu.playlist_items(playlist, limit=100, offset=100 * page)\n",
    "        \n",
    "        for item in data['items']:\n",
    "            if item['track'] is None or item['track']['type'] == 'episode':\n",
    "                continue\n",
    "            track_ids.append(item['track']['id'])\n",
    "            track_names.append(item['track']['name'])\n",
    "            artist_ids.append(item['track']['artists'][0]['id'])\n",
    "            artist_names.append(item['track']['artists'][0]['name'])\n",
    "            release_date.append(item['track']['album']['release_date'])\n",
    "            popularity.append(item['track']['popularity'])\n",
    "            length.append(item['track']['duration_ms'])\n",
    "    \n",
    "    data_track = {\n",
    "        'name': track_names,\n",
    "        'id': track_ids,\n",
    "        'artist': artist_names,\n",
    "        'artist_id': artist_ids,\n",
    "        'popularity': popularity,\n",
    "        'release_date': release_date,\n",
    "        'length': length\n",
    "    }\n",
    "    \n",
    "    df_track = pd.DataFrame(data_track)\n",
    "    return df_track\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5663e9-d671-44cf-85e2-5c2837abd560",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_songs_df = get_playlist_songs(playlist_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf79add-d04b-46ac-bc31-a5244f472db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting artist data like genre and popularity from these songs\n",
    "\n",
    "distinct_artists = unique_songs_df.artist_id.unique().tolist()\n",
    "\n",
    "artist_list = []\n",
    "genre_list = []\n",
    "popularity_list = []\n",
    "artist_name = []\n",
    "\n",
    "def artist_analysis(artist_id_list):\n",
    "    \n",
    "    for artist_id in artist_id_list:\n",
    "        artist = spu.artist(artist_id)\n",
    "        for num_genre in range(len(artist['genres'])):\n",
    "            artist_list.append(artist_id)\n",
    "            artist_name.append(artist['name'])\n",
    "            popularity_list.append(artist['popularity'])\n",
    "            genre_list.append(artist['genres'][num_genre])\n",
    "    \n",
    "    data = {'artist_id': artist_list, 'artist': artist_name, 'artist_popularity': popularity_list, 'genre': genre_list}\n",
    "    df_genres = pd.DataFrame(data)\n",
    "    return df_genres\n",
    "\n",
    "genres = artist_analysis(distinct_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1471fe-f2bf-4635-bae0-214ab9a4c857",
   "metadata": {},
   "source": [
    "### 2. Get lyrics from Genius"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694abd9b-b15b-48a4-b0e8-bc5854fd582f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# genius api credentials login\n",
    "LyricsGenius = lyricsgenius.Genius(\n",
    "    genius_access_token, verbose = True, skip_non_songs = True, timeout = 15\n",
    ")\n",
    "\n",
    "keywords = ['chorus', 'instrumental', 'bridge', 'verse', 'embed', 'lyrics', 'outro', 'intro']\n",
    "lyrics_df = []\n",
    "\n",
    "# searching for lyrics for each song\n",
    "\n",
    "def genius_search(song, artist):\n",
    "    lyrics = ''\n",
    "    retries = 0\n",
    "    while retries < 3:\n",
    "        try:\n",
    "            track = LyricsGenius.search_song(song, artist)\n",
    "            \n",
    "            # ensure track is not None and contains lyrics\n",
    "            if track is None:\n",
    "                retries += 1\n",
    "                continue\n",
    "            \n",
    "            # process the lyrics line by line\n",
    "            for line in track.lyrics.lower().split('\\n'):\n",
    "                if not any(keyword in line.lower() for keyword in keywords):\n",
    "                    lyrics += line+' '\n",
    "                    \n",
    "            return lyrics\n",
    "        \n",
    "        except TimeoutError as e:  \n",
    "            retries += 1\n",
    "\n",
    "    # if it fails after 3 retries, return an empty string\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57203c02-db28-4cbd-b62b-2aa59237cbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataframe with all song lyrics\n",
    "lyrics_df = pd.DataFrame(columns=['song', 'artist', 'lyrics'])\n",
    "\n",
    "for song, artist in unique_songs_df[['name','artist']].itertuples(index=False):\n",
    "    lyrics = genius_search(song, artist)\n",
    "    time.sleep(1)\n",
    "    \n",
    "    temp_df = pd.DataFrame([[song, artist, lyrics]], columns=['song', 'artist', 'lyrics'])\n",
    "    lyrics_df = pd.concat([lyrics_df, temp_df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fffff52-905a-4d67-8af1-14e4e6d2e37b",
   "metadata": {},
   "source": [
    "### 3. Feature engineering and modeling on Genius lyrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf63583-4ab9-4cca-8cb9-6c2027ee3afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentiment analysis on lyrics using pre-trained model\n",
    "\n",
    "def get_sentiment(text):\n",
    "    analysis = TextBlob(text)\n",
    "    return analysis.sentiment.polarity  # returns a polarity score between -1 (negative) and +1 (positive)\n",
    "\n",
    "lyrics_df['sentiment'] = lyrics_df['lyrics'].apply(get_sentiment)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172d0dd8-b2fd-4292-9b6c-b21f508bae44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature engineering on lyrics for clustering\n",
    "# genius sometimes has random novels/lists instead of lyrics so we're using clustering to automatically remove them\n",
    "\n",
    "lyrics_df.replace('', np.nan, inplace=True)\n",
    "lyrics_df = lyrics_df.dropna(subset=['lyrics'])\n",
    "\n",
    "\n",
    "def count_numbers(text):\n",
    "    return len(re.findall(r'\\d+', text))\n",
    "\n",
    "# Apply function to each row of the 'lyrics' column\n",
    "lyrics_df['num_numbers'] = lyrics_df['lyrics'].apply(count_numbers)\n",
    "\n",
    "def count_dashes(text):\n",
    "    return len(re.findall(r' - ', text))\n",
    "\n",
    "lyrics_df['num_dashes'] = lyrics_df['lyrics'].apply(count_dashes)\n",
    "\n",
    "def count_words(text):\n",
    "    return len(text.split())\n",
    "\n",
    "lyrics_df['num_words'] = lyrics_df['lyrics'].apply(count_words)\n",
    "\n",
    "def count_periods(text):\n",
    "    return len(re.findall(r'\\.', text))\n",
    "\n",
    "lyrics_df['num_period'] = lyrics_df['lyrics'].apply(count_periods)\n",
    "\n",
    "lyrics_df['num_per_word'] = lyrics_df['num_words'] / np.where(lyrics_df['num_numbers'] == 0, 1, lyrics_df['num_numbers'])\n",
    "\n",
    "lyrics_df = lyrics_df[lyrics_df['num_words'] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9374af1b-3b17-47c8-8c95-27847caf6a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing my saved clustering model to remove these entries\n",
    "\n",
    "kmeans = joblib.load('kmeans_model.pkl')\n",
    "scaler = joblib.load('scaler.pkl')\n",
    "\n",
    "new_df = lyrics_df[['num_numbers','num_dashes','num_words','num_period','num_per_word']]\n",
    "\n",
    "scaled_new_features = scaler.transform(new_df)\n",
    "\n",
    "new_clusters = kmeans.predict(scaled_new_features)\n",
    "\n",
    "# add the cluster labels to the new dataset\n",
    "new_df['cluster'] = new_clusters\n",
    "lyrics_df['cluster'] = new_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac443f7-f511-477f-a48b-c92550e68341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# keeping only my 0-cluster (true lyrics)\n",
    "final_lyrics = lyrics_df[lyrics_df['cluster']==0].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bd710e6b-0e4a-46ab-8242-32bd5b130c6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fce8d70dd30c4856829d7e40f2c43668",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/919 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2fb4b241bd174cb48bc7625d97a4ca17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990438634f0b4919a397aaa1ae34329b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ddd8740a9fe34b109813d70b5fbc8cc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1f3f866b9864979b451c59b694efdb2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and tokenizer successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "# importing my saved nlp classification model\n",
    "\n",
    "# Load the model and tokenizer from Hugging Face Hub\n",
    "repo_id = \"emmakrentz/bert-classification-model\"  # Replace with your repo ID\n",
    "\n",
    "model = BertForSequenceClassification.from_pretrained(repo_id)\n",
    "tokenizer = BertTokenizer.from_pretrained(repo_id)\n",
    "\n",
    "print(\"Model and tokenizer successfully loaded!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca23bb1e-925f-4e1a-89a9-eb14df5ac138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nlp classification of song lyrics to seasons\n",
    "\n",
    "import torch\n",
    "\n",
    "label_mapping = {0:'fall', 1:'spring', 2:'summer', 3:'winter'}\n",
    "\n",
    "def predict_lyrics(texts):\n",
    "    # tokenize the batch of text\n",
    "    inputs = tokenizer(texts, return_tensors=\"pt\", padding=True, truncation=True, max_length=256)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "\n",
    "    # get predictions\n",
    "    logits = outputs.logits\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "    predicted_labels = torch.argmax(probabilities, dim=1).tolist()\n",
    "    \n",
    "    # map back to original labels and return\n",
    "    mapped_labels = [label_mapping[label] for label in predicted_labels]\n",
    "    return mapped_labels, probabilities.tolist()\n",
    "\n",
    "# run predictions on lyrics\n",
    "texts = final_lyrics[\"lyrics\"].tolist()\n",
    "batch_size = 16  \n",
    "predicted_labels = []\n",
    "all_probabilities = []\n",
    "\n",
    "for i in range(0, len(texts), batch_size):\n",
    "    batch = texts[i:i+batch_size]\n",
    "    labels, probabilities = predict_lyrics(batch)\n",
    "    predicted_labels.extend(labels)\n",
    "    all_probabilities.extend(probabilities)\n",
    "\n",
    "# add predictions back to df\n",
    "final_lyrics[\"predicted_season\"] = predicted_labels\n",
    "final_lyrics[\"prob\"] = all_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fee9c3-f7cc-43df-b4aa-b4721cf463ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine what most-listened to season was\n",
    "\n",
    "group_sizes = final_lyrics.groupby('predicted_season').size()\n",
    "\n",
    "largest_group = group_sizes.idxmax()\n",
    "\n",
    "# access the highest indexed entries in that group\n",
    "largest_group_data = final_lyrics[final_lyrics['predicted_season'] == largest_group]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17fc335d-8962-4294-9295-9caf3918b151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gay\n",
    "\n",
    "gay_artists = ['Chappell Roan','girl in red','MUNA','Charli XCX','Whitney Houston','Mariah Carey',\n",
    "               'Britney Spears','Sidney Gish','The Last Dinner Party','Tegan and Sara','Kylie Minogue']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a208778-2854-4397-8e75-2c68c2d7ff86",
   "metadata": {},
   "source": [
    "### 4. Creating output images based on data results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2821a529-aef9-4012-a766-de1636740fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENRES\n",
    "\n",
    "# Load the image\n",
    "input_image_path = \"templates_unwrapped/9.png\"\n",
    "output_image_path = \"output_unwrapped/06.png\"\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(input_image_path)\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define the text, font, and position\n",
    "font_path = 'Recoleta-Bold.ttf'#\"GothamBold.ttf\"  # Replace with the path to your desired font file\n",
    "font_size = 90  # Adjust font size as needed\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "height = [680,1050,1420]\n",
    "for x in range(3):\n",
    "    if len(genres.groupby('genre').size().sort_values(ascending=True).index[x])<=13:\n",
    "        draw.text((420,height[x]), genres.groupby('genre').size().sort_values(ascending=True).index[x], fill=\"white\", font=font)\n",
    "    else:\n",
    "        draw.text((420,height[x]-40), genres.groupby('genre').size().sort_values(ascending=True).index[x].split()[0], fill=\"white\", font=font)        \n",
    "        draw.text((420,height[x]+40), genres.groupby('genre').size().sort_values(ascending=True).index[x].split()[1], fill=\"white\", font=font)        \n",
    "            \n",
    "# Save the edited image\n",
    "image.save(output_image_path)\n",
    "\n",
    "print(f\"Edited image saved as {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d8135a-046f-40a3-8a09-607e9b30b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP GENRE\n",
    "\n",
    "input_image_path = \"templates_unwrapped/11.png\"\n",
    "output_image_path = \"output_unwrapped/07.png\"\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(input_image_path)\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define the text, font, and position\n",
    "font_path = 'Recoleta-Bold.ttf'#\"GothamBold.ttf\"  # Replace with the path to your desired font file\n",
    "font_size = 130  # Adjust font size as needed\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "if len(genres.groupby('genre').size().sort_values(ascending=False).index[0])<=13:\n",
    "    draw.text((250,1150),genres.groupby('genre').size().sort_values(ascending=False).index[0], fill=\"white\", font=font)\n",
    "else:\n",
    "    draw.text((250,1150),genres.groupby('genre').size().sort_values(ascending=False).index[0].split()[0], fill=\"white\", font=font)\n",
    "    draw.text((250,1250),genres.groupby('genre').size().sort_values(ascending=False).index[0].split()[1], fill=\"white\", font=font)\n",
    "    \n",
    "         \n",
    "# Save the edited image\n",
    "image.save(output_image_path)\n",
    "\n",
    "print(f\"Edited image saved as {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763d9528-648d-44f7-b80f-efbd9b04a2dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SENTIMENT\n",
    "\n",
    "input_image_path = \"templates_unwrapped/13.png\"\n",
    "output_image_path = \"output_unwrapped/08.png\"\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(input_image_path)\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define the text, font, and position\n",
    "font_path = 'Recoleta-Bold.ttf'#\"GothamBold.ttf\"  # Replace with the path to your desired font file\n",
    "font_size = 130  # Adjust font size as needed\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "draw.text((185,620), str(round(lyrics_df['sentiment'].sum()/lyrics_df['sentiment'].abs().sum()*100))+'%', fill=\"white\", font=font)\n",
    "         \n",
    "# Save the edited image\n",
    "image.save(output_image_path)\n",
    "\n",
    "print(f\"Edited image saved as {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6693ad-369d-41c0-a636-eedd51341aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HAPPY AND SAD SONGS\n",
    "input_image_path = \"templates_unwrapped/15.png\"\n",
    "output_image_path = \"output_unwrapped/09.png\"\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(input_image_path)\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define the text, font, and position\n",
    "font_path = \"GothamBold.ttf\"  # Replace with the path to your desired font file\n",
    "font_size = 55  # Adjust font size as needed\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "artist_font_size = 30\n",
    "artist_font = ImageFont.truetype(font_path, artist_font_size)\n",
    "\n",
    "height = [370,520,670,820]\n",
    "for x in range(4):\n",
    "    draw.text((130,height[x]), lyrics_df.sort_values(by='sentiment',ascending=False).reset_index(drop=True).loc[x,'song'], fill=\"white\", font=font)\n",
    "    draw.text((130,height[x]+65), lyrics_df.sort_values(by='sentiment',ascending=False).reset_index(drop=True).loc[x,'artist'], fill=\"white\", font=artist_font)\n",
    "    draw.text((130,height[x]+800), lyrics_df.sort_values(by='sentiment',ascending=True).reset_index(drop=True).loc[x,'song'], fill=\"white\", font=font)\n",
    "    draw.text((130,height[x]+865), lyrics_df.sort_values(by='sentiment',ascending=True).reset_index(drop=True).loc[x,'artist'], fill=\"white\", font=artist_font)\n",
    "\n",
    "# Save the edited image\n",
    "image.save(output_image_path)\n",
    "\n",
    "print(f\"Edited image saved as {output_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e10635b-c370-4977-8073-efd4b044fbbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SEASON\n",
    "\n",
    "if final_lyrics.groupby('predicted_season').size().idxmax() == 'winter':\n",
    "    \n",
    "    input_image_path = \"templates_unwrapped/winter.png\"\n",
    "    output_image_path = \"output_unwrapped/03.png\"\n",
    "\n",
    "elif final_lyrics.groupby('predicted_season').size().idxmax() == 'fall':\n",
    "    \n",
    "    input_image_path = \"templates_unwrapped/autumn.png\"\n",
    "    output_image_path = \"output_unwrapped/03.png\"\n",
    "\n",
    "elif final_lyrics.groupby('predicted_season').size().idxmax() == 'spring':\n",
    "    \n",
    "    input_image_path = \"templates_unwrapped/spring.png\"\n",
    "    output_image_path = \"output_unwrapped/03.png\"\n",
    "\n",
    "elif final_lyrics.groupby('predicted_season').size().idxmax() == 'summer':\n",
    "    \n",
    "    input_image_path = \"templates_unwrapped/summer.png\"\n",
    "    output_image_path = \"output_unwrapped/03.png\"\n",
    "    \n",
    "# Open the image\n",
    "image = Image.open(input_image_path)\n",
    "    \n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "    \n",
    "# Define the text, font, and position\n",
    "font_path = \"GothamBold.ttf\"  # Replace with the path to your desired font file\n",
    "font_size = 55  # Adjust font size as needed\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "    \n",
    "artist_font_size = 30\n",
    "artist_font = ImageFont.truetype(font_path, artist_font_size)\n",
    "    \n",
    "height = [850,1000,1150,1300]\n",
    "for x in range(4):\n",
    "    draw.text((220,height[x]), largest_group_data.reset_index(drop=True).loc[x,'song'], fill=\"white\", font=font)\n",
    "    draw.text((220,height[x]+65), largest_group_data.reset_index(drop=True).loc[x,'artist'], fill=\"white\", font=artist_font)\n",
    "\n",
    "# Save the edited image\n",
    "image.save(output_image_path)\n",
    "    \n",
    "print(f\"Edited image saved as {output_image_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd0efb5-e862-47e6-8092-e82592772902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEAST POPULAR ARTIST\n",
    "\n",
    "# Input and output paths\n",
    "input_image_path = \"templates_unwrapped/7.png\"\n",
    "output_image_path = \"output_unwrapped/05.png\"\n",
    "font_path = 'Recoleta-Bold.ttf'  # Ensure the font file is in the correct location\n",
    "\n",
    "# Get the smallest artist's image URL and name\n",
    "artist_data = genres.sort_values(by='artist_popularity').reset_index(drop=True).loc[0]\n",
    "artist_name = artist_data['artist']\n",
    "url_image_url = spu.artist(artist_data['artist_id'])['images'][0]['url']\n",
    "\n",
    "try:\n",
    "    # Open the main image\n",
    "    image = Image.open(input_image_path)\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # Fetch the overlay image from the URL\n",
    "    response = requests.get(url_image_url)\n",
    "    response.raise_for_status()  # Check for HTTP errors\n",
    "    overlay_image = Image.open(BytesIO(response.content))\n",
    "\n",
    "    # Optional: Resize the overlay image\n",
    "    overlay_image = overlay_image.resize((500, 500))  # Adjust size as needed\n",
    "\n",
    "    # Define overlay position and paste\n",
    "    overlay_position = (300, 650)  # Adjust based on your layout\n",
    "    image.paste(overlay_image, overlay_position)\n",
    "\n",
    "    # Load font\n",
    "    if not os.path.exists(font_path):\n",
    "        raise FileNotFoundError(f\"Font file not found: {font_path}\")\n",
    "    font_size = 80\n",
    "    font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "    # Draw artist name\n",
    "    text_position = (300, 1180)\n",
    "    draw.text(text_position, artist_name, fill=\"white\", font=font)\n",
    "\n",
    "    # Save the edited image\n",
    "    image.save(output_image_path)\n",
    "    print(f\"Edited image saved as {output_image_path}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c4d417-808f-4612-9756-b1821d7eab0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GAYOMETER\n",
    "\n",
    "input_image_path = \"templates_unwrapped/18.png\"\n",
    "output_image_path = \"output_unwrapped/11.png\"\n",
    "\n",
    "# Open the image\n",
    "image = Image.open(input_image_path)\n",
    "\n",
    "# Create a drawing object\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Define the text, font, and position\n",
    "font_path = 'Recoleta-Bold.ttf'#\"GothamBold.ttf\"  # Replace with the path to your desired font file\n",
    "font_size = 140  # Adjust font size as needed\n",
    "font = ImageFont.truetype(font_path, font_size)\n",
    "\n",
    "draw.text((700,380), str(round(sum(item in gay_artists for item in unique_songs_df.artist.tolist())/len(unique_songs_df.artist.tolist())*100))+'%', fill=\"white\", font=font)\n",
    "         \n",
    "# Save the edited image\n",
    "image.save(output_image_path)\n",
    "\n",
    "print(f\"Edited image saved as {output_image_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba738b-c49c-479c-b8c6-b5e22699a24e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
